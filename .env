# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=llama2:7b

# Data Paths (optional - defaults are set in config.py)
# HTS_BASE_URL=https://hts.usitc.gov
# VECTOR_DB_PATH=data/vector_db
# SQLITE_DB_PATH=data/hts_data.db

# Model Settings (optional - defaults are set)
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=200

# Model Configuration
# Set to "true" to use remote API instead of local Ollama
USE_REMOTE_API=false

# Remote API Configuration (choose one)
REMOTE_MODEL_PROVIDER=openai  # options: openai, anthropic, together

# API Keys (only set the one you're using)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
TOGETHER_API_KEY=your_together_api_key_here

# Model Selection
# For OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo
# For Anthropic: claude-3-sonnet-20240229, claude-3-haiku-20240307
# For Together: meta-llama/Llama-2-70b-chat-hf, mistralai/Mixtral-8x7B-Instruct-v0.1
REMOTE_MODEL_NAME=gpt-3.5-turbo

# Local Ollama Configuration (when USE_REMOTE_API=false)
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=llama2:7b